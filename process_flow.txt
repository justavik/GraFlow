GraFlow Pipeline: Executive Process Flow

1. PDF INPUT

1.1 File Discovery and Validation
The orchestrator scans input directories for PDF files, validates file accessibility and format, then establishes baseline metrics including file count and total size for processing optimization.

1.2 Directory Structure Initialization
Creates complete directory hierarchy including processed_text, graphrag_input, and graphrag_output folders. Validates Stirling PDF API connectivity and system dependencies before processing begins.

1.3 Processing Queue Management
Analyzes PDF characteristics to construct optimized processing queue. Implements error handling, retry logic, and detailed logging for robust document processing workflow.

2. STIRLING PDF PROCESSING

2.1 Primary Text Extraction Strategy
Uses Stirling PDF's /api/v1/convert/pdf/text endpoint with Apache PDFBox for direct text stream extraction. Achieves 1-5 second processing per document while preserving formatting and metadata.

2.2 OCR Fallback Processing
Automatically switches to /api/v1/misc/ocr-pdf endpoint using Tesseract OCR when direct extraction fails. Converts pages to images, applies preprocessing, and performs multi-language character recognition.

2.3 Output Validation and Quality Assurance
Validates extracted text quality through character count analysis, encoding verification, and structural integrity checks. Implements retry mechanisms for failed extractions with detailed quality metrics.

3. TEXT CLEANING AND CHUNKING

3.1 Text Normalization and Preprocessing
Removes PDF artifacts including excessive whitespace, page numbers, and headers using regex patterns. Handles encoding issues and Unicode normalization for consistent text representation.

3.2 Content Structure Analysis and Preservation
Identifies and preserves structural elements like section headers, paragraphs, and tables crucial for entity extraction. Distinguishes meaningful content from pagination artifacts using heuristic algorithms.

3.3 Optimization for GraphRAG Ingestion
Standardizes format and encoding (UTF-8) while creating processing-ready files optimized for GraphRAG requirements. Generates metadata including character counts and complexity indicators for configuration tuning.

4. PROCESSED TEXT

4.1 Text Unit Organization and Staging
Organizes cleaned files into GraphRAG-compatible format with systematic naming conventions and metadata. Ensures traceability to original sources while conforming to GraphRAG input requirements.

4.2 Quality Verification and Metrics Collection
Performs final quality checks including character count validation and content density analysis. Establishes baseline metrics for knowledge extraction including processing time estimates and entity density indicators.

4.3 GraphRAG Input Preparation
Copies processed files to GraphRAG project structure with proper permissions and directory organization. Validates file accessibility and encoding before the computationally intensive indexing phase.

5. KNOWLEDGE GRAPH GENERATION

5.1 GraphRAG Initialization and Configuration Management
Initializes project with settings_fast.yaml deployment and API connectivity validation for Groq LLM and OpenAI services. Configures concurrency parameters (10 Groq, 15 OpenAI requests) with rate limiting strategies.

5.2 Multi-Phase Knowledge Extraction Process
Executes seven-phase process: text chunking (1200-token units), entity/relationship extraction, deduplication, community detection with Leiden Algorithm, and summarization. Requires 1500-2500 API calls per 1000-page document.

5.3 Graph Augmentation and Optimization
Applies Hierarchical Leiden Algorithm for community detection and generates executive summaries. Creates final artifacts: entities.parquet, relationships.parquet, communities.parquet, and community_reports.parquet with vector embeddings.

6. GRAPHRAG QUERYING

6.1 Query Interface Initialization and Index Validation
Validates completed knowledge graph structure including entity databases, relationship mappings, and vector embeddings. Establishes processing pipelines for both global and local query methodologies.

6.2 Global Search Processing for Broad Knowledge Synthesis
Leverages community reports for broad questions about document themes and cross-cutting topics. Combines multiple community reports using LLM synthesis for comprehensive answers spanning entire document collections.

6.3 Local Search Processing for Specific Entity Queries
Focuses on specific entities using detailed relationship networks for precise answers. Retrieves entity neighborhoods and relevant text units to provide grounded, traceable responses to factual queries.
